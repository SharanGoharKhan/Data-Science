{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Assignment No 4b\n",
    "###### *Sibt ul Hussain*\n",
    "----\n",
    "## Goal\n",
    "\n",
    "Your goal in this part of assigment is to implement a Decision Tree Classifier for categorical variables.\n",
    "\n",
    "**Note** Please note that you are allowed to use only those libraries which we have discussed in the class, i.e. numpy, scipy, pandas.\n",
    "\n",
    "## Submission Instructions\n",
    "You are required to submit the original notebook file on the Slate (with .ipynb extension), with complete set of outputs. Students failing to do so will get zero marks. \n",
    "\n",
    "*Please read each step carefully and understand it fully before proceeding with code writing*\n",
    "\n",
    "## Plagiarism\n",
    "Any form of plagiarism will not be tolerated and result in 0 marks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier\n",
    "\n",
    "Now in this assignment we will be implementing the Decision Classifier for both Continuous and Categorical attributes.\n",
    "\n",
    "Decision tree can be built by using any of the following split criterias, namely:\n",
    " - Information Gain\n",
    " - Gini Index\n",
    " - CART \n",
    "\n",
    "However, you are required here to implement the decision tree with information gain as splitting criterion.\n",
    "\n",
    "Remember in my code i am not looking for maximizing the information gain, instead i am looking for minimizing the split entropy. Recall,\n",
    "$$Information Gain  = H(D) - H(D_Y,D_N)$$\n",
    "\n",
    "Where,\n",
    "\n",
    "$H(D)$ is the data set entroy and $H(D_Y,D_N)$ is split entropy. Since $H(D)$ is constant for the given dataset so maximizing the entropy is equal to minimizing the split entropy and that is what is being represented in my code outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import scipy.stats\n",
    "#from collections import defaultdict\n",
    "import pandas as pd\n",
    "import tools as t\n",
    "from math import log\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from collections import defaultdict, Counter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSplits(categories):\n",
    "    '''\n",
    "        function returns list of splits for the given list of categorical variables...\n",
    "        \n",
    "        Input:\n",
    "        ------------\n",
    "            categories: a list of unique categories...\n",
    "        \n",
    "        Return:\n",
    "        ------------\n",
    "            list of splits(tuples) for given list of categorical variables. Each pair of sublists\n",
    "            defines the left and right splits, e.g. This list\n",
    "            [('y', 'f'), ('s', 'g'), ('f'), ('y', 's', 'g')]\n",
    "            \n",
    "            defines two splits with each pair representing a different split.\n",
    "        Examples:\n",
    "        ------------\n",
    "        splits=getSplits(['a1','a2','a3','a4']) will return \n",
    "        [('a1', 'a2', 'a4'), ('a3',), ('a2', 'a4'), \n",
    "        ('a1', 'a3'), ('a1', 'a4'), ('a3', 'a2'), ('a1', 'a3', 'a2'), \n",
    "        ('a4',), ('a3', 'a4'), ('a1', 'a2'), ('a1',), ('a3', 'a2', 'a4'), ('a2',), ('a1', 'a3', 'a4')]\n",
    "\n",
    "            \n",
    "    '''\n",
    "    categories=set(categories)\n",
    "    tsplits=t.get_powerset(categories,len(categories)-1)\n",
    "    flist=[]\n",
    "    for s in tsplits:\n",
    "        if not s in flist:\n",
    "            r=categories.difference(s)\n",
    "            flist.append(s)\n",
    "            flist.append(r)\n",
    "    olist=[]\n",
    "    for s in flist:\n",
    "        ilist=[]\n",
    "        for k in s:\n",
    "            ilist.append(k)\n",
    "        olist.append(tuple(ilist))\n",
    "    return olist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a1', 'a2', 'a4'), ('a3',), ('a2', 'a4'), ('a1', 'a3'), ('a1', 'a4'), ('a3', 'a2'), ('a1', 'a3', 'a2'), ('a4',), ('a3', 'a4'), ('a1', 'a2'), ('a1',), ('a3', 'a2', 'a4'), ('a2',), ('a1', 'a3', 'a4')] 14\n"
     ]
    }
   ],
   "source": [
    "splits=getSplits(['a1','a2','a3','a4'])\n",
    "print splits,len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,purity,klasslabel='',score=0,split=[],fidx=-1):\n",
    "        '''\n",
    "            purity: purity level at which to stop\n",
    "            klasslabel: klasslabel of the node, (for leaf node)\n",
    "            score: information gain of the newly added node\n",
    "            split: splitting threshold\n",
    "            fidx: feature index            \n",
    "        '''\n",
    "        self.lchild=None\n",
    "        self.rchild=None\n",
    "        self.klasslabel=klasslabel        \n",
    "        self.split=split\n",
    "        self.score=score\n",
    "        self.fidx=fidx\n",
    "        self.purity=purity\n",
    "        self.ftype= 'categorical' if type(self.split) in [tuple, str, numpy.string_] else 'continuous' # feature type \n",
    "\n",
    "        \n",
    "    def set_childs(self,lchild,rchild):\n",
    "        # YOUR CODE HERE\n",
    "        self.lchild=lchild\n",
    "        self.rchild=rchild\n",
    "        \n",
    "    def isleaf(self):\n",
    "        # YOUR CODE HERE\n",
    "        if (self.lchild is None)&(self.rchild is None):\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def isless_than_eq(self, X):\n",
    "        # YOUR CODE HERE\n",
    "        if self.ftype=='categorical':\n",
    "            if X[self.fidx] in self.split:\n",
    "                return True\n",
    "            return False\n",
    "        else:\n",
    "            if X[self.fidx] <= self.split:\n",
    "                return True\n",
    "            return False\n",
    "        \n",
    "    def get_str(self):        \n",
    "        if self.isleaf():\n",
    "            return 'C(class={},Purity={})'.format(self.klasslabel,self.purity)\n",
    "        else:\n",
    "            return 'I(Fidx={},Score={},Split={})'.format(self.fidx,self.score,self.split) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, purityp, exthreshold, maxdepth=10):        \n",
    "        self.purity = purityp\n",
    "        self.exthreshold = exthreshold\n",
    "        self.maxdepth = maxdepth\n",
    "        pass\n",
    "    def train(self, X, Y):\n",
    "        nexamples, nfeatures = X.shape\n",
    "        self.tree=self.build_tree(X,Y,0)\n",
    "    def build_tree(self, X, Y,depth):\n",
    "        nexamples, nfeatures = X.shape\n",
    "        klasses,klasses_counts=np.unique(Y,return_counts=True);\n",
    "        nexamples=nexamples*1.0\n",
    "        leafLabel = \"\"\n",
    "        purityd=0\n",
    "        for k in klasses:\n",
    "            temp = np.count_nonzero(Y[Y == k]) / nexamples\n",
    "            if(temp > purityd):\n",
    "                purityd = temp\n",
    "                leafLabel = k\n",
    "        if depth >= self.maxdepth or purityd >= self.purity or nexamples <= self.exthreshold:\n",
    "            node=Node(purityd,klasslabel=leafLabel)\n",
    "        else:\n",
    "            splitS=+np.inf\n",
    "            splitP=0\n",
    "            onfe=0\n",
    "            SDY=[]\n",
    "            SDN=[]\n",
    "            for fe in xrange(nfeatures):\n",
    "                self.classes=np.unique(Y)\n",
    "                self.nclasses=len(np.unique(Y))\n",
    "                if type(X[0,fe]) is int  or float:\n",
    "                    val,sco,dn,dy=self.evaluate_numerical_attribute(X[:,fe],Y)\n",
    "                else:\n",
    "                    if(len(np.unique(X[:,fe]))>1):\n",
    "                        val,sco,dn,dy=self.evaluate_categorical_attribute(X[:,fe],Y)\n",
    "                    else:\n",
    "                        if nfeatures<2:\n",
    "                            for k in klasses:\n",
    "                                temp = np.count_nonzero(Y[Y == k]) / nexamples\n",
    "                                if(temp > purityd):\n",
    "                                    purityd = temp\n",
    "                                    leafLabel = k\n",
    "                            return Node(purityd,KlassLabel=leafLabel)\n",
    "                        else:\n",
    "                            sco=+np.inf\n",
    "                if splitS > sco:\n",
    "                    splitS=sco\n",
    "                    splitP=val\n",
    "                    SDN=dn\n",
    "                    SDY=dy\n",
    "                    onfe=fe\n",
    "            if splitP==0:\n",
    "                for k in klasses:\n",
    "                                temp = np.count_nonzero(Y[Y == k]) / nexamples\n",
    "                                if(temp > purityd):\n",
    "                                    purityd = temp\n",
    "                                    leafLabel = k\n",
    "                node=Node(purityd,klasslabel=leafLabel)\n",
    "            else:\n",
    "                node=Node(purityd,score=splitS,split=splitP,fidx=onfe)\n",
    "                node.lchild=self.build_tree(X[SDN,:],Y[SDN],depth+1)\n",
    "                node.rchild=self.build_tree(X[SDY,:],Y[SDY],depth+1)\n",
    "        return node\n",
    "    def test(self, X):\n",
    "        nexamples, nfeatures = X.shape\n",
    "        pclasses = self.predict(X)\n",
    "        return np.array(pclasses)\n",
    "    def evaluate_categorical_attribute(self, feat, Y):\n",
    "            categories = set(feat)\n",
    "            splits = getSplits(categories) if len(categories) > 1 else tuple(categories)\n",
    "            freq = scipy.stats.itemfreq(Y)\n",
    "            f=np.array(feat)\n",
    "            classes = np.unique(Y)\n",
    "            nclasses = len(classes)\n",
    "            csplit=0\n",
    "            mingain=+np.inf\n",
    "            for i in range(0,len(splits),2):\n",
    "                probdn=0.0\n",
    "                for atr in splits[i]:\n",
    "                    probdn+=(f==atr).sum()\n",
    "                probdy=len(f)-probdn\n",
    "                hdn=0\n",
    "                hdy=0\n",
    "                for cl in classes:\n",
    "                    tmp=f[Y==cl]\n",
    "                    tmp1=0.0\n",
    "                    for atr in splits[i]:\n",
    "                        tmp1+=(tmp==atr).sum()\n",
    "                    tmp1=tmp1*1.0\n",
    "                    if tmp1>0:\n",
    "                        hdn+=(tmp1/probdn)*np.log2(tmp1/probdn)\n",
    "                    tmp=f[Y!=cl]\n",
    "                    tmp1=0\n",
    "                    for atr in splits[i+1]:\n",
    "                        tmp1+=(tmp==atr).sum()\n",
    "                    tmp1=tmp1*1.0\n",
    "                    if tmp1>0:\n",
    "                        hdy+=(tmp1/probdy)*np.log2(tmp1/probdy)\n",
    "                hdn=hdn*((probdn*1.0)/(probdn+probdy))*(-1)\n",
    "                hdy=hdy*((probdy*1.0)/(probdn+probdy))*(-1)\n",
    "                if ((hdn+hdy) < mingain):\n",
    "                    csplit=splits[i]\n",
    "                    mingain=hdn+hdy\n",
    "            Xlidx=(f==csplit[0])\n",
    "            for i in range(1,len(csplit)):\n",
    "                Xlidx=np.asarray(f==csplit[i])|np.asarray(Xlidx)\n",
    "            Xridx=~Xlidx\n",
    "            return csplit, mingain, Xlidx, Xridx\n",
    "    def evaluate_numerical_attribute(self, feat, Y):\n",
    "        classes = np.unique(Y)\n",
    "        nclasses = len(classes)\n",
    "        sidx=np.argsort(feat)\n",
    "        f=feat[sidx]\n",
    "        sY=Y[sidx]\n",
    "        Midpoints=set()\n",
    "        nt=defaultdict(int)\n",
    "        N={}\n",
    "        for i in xrange(nclasses):\n",
    "            nt[classes[i]]=0\n",
    "        for i in xrange(len(f)-1):\n",
    "            nt[sY[i]]+=1\n",
    "            if f[i]!=f[i+1]:\n",
    "                v=(f[i]+f[i+1])/2\n",
    "                Midpoints.add(v)\n",
    "                N[v]=nt.values()\n",
    "        nt[sY[len(f)-1]]+=1\n",
    "        n={}\n",
    "        for i,tmp in enumerate(nt.keys()):\n",
    "            n[i]=nt[tmp]*1.0\n",
    "        split=0\n",
    "        mingain=+np.inf\n",
    "        for v in Midpoints:\n",
    "            en_dy=0.0\n",
    "            en_dn=0.0\n",
    "            for i in xrange(nclasses):\n",
    "                tmp=N[v][i]*1.0\n",
    "                if tmp > 0.0:\n",
    "                    en_dy+=(tmp/sum(N[v]))*np.log2(tmp/sum(N[v]))\n",
    "                tmp1=(n[i]-tmp)*1.0\n",
    "                if tmp1 > 0.0:\n",
    "                    en_dn+=(tmp1/sum(n.values()-np.array(N[v])))*np.log2(tmp1/sum(n.values()-np.array(N[v])))\n",
    "            tmp=((sum(N[v])*1.0)/sum(n.values()))\n",
    "            gain=(-1)*((en_dy*tmp)+(en_dn*(1.0-tmp)))\n",
    "            if (gain < mingain):\n",
    "                split=v\n",
    "                mingain=gain\n",
    "        temp=np.array((feat))\n",
    "        Xlidx=temp<split\n",
    "        Xridx=temp>split\n",
    "        return split,mingain,Xlidx,Xridx\n",
    "    def predict(self, X):\n",
    "        z = []\n",
    "        for idx in range(X.shape[0]):\n",
    "            z.append(self._predict(self.tree, X[idx, :]))\n",
    "        return z \n",
    "    def _predict(self, node, X):\n",
    "        if node.isleaf():\n",
    "            return node.klasslabel\n",
    "        if node.isless_than_eq(X):\n",
    "            return self._predict(node.lchild,X)\n",
    "        return self._predict(node.rchild,X)\n",
    "    def __str__(self):\n",
    "        str = '---------------------------------------------------'\n",
    "        str += '\\n A Decision Tree With Depth={}'.format(self.find_depth())\n",
    "        str += self.__print(self.tree)\n",
    "        str += '\\n---------------------------------------------------'\n",
    "        return str\n",
    "    def find_depth(self):\n",
    "        return self._find_depth(self.tree)\n",
    "    def _find_depth(self, node):\n",
    "        if not node:\n",
    "            return\n",
    "        if node.isleaf():\n",
    "            return 1\n",
    "        else:\n",
    "            return max(self._find_depth(node.lchild), self._find_depth(node.rchild)) + 1\n",
    "    def __print(self, node, depth=0):\n",
    "        ret = \"\"\n",
    "        if node.rchild:\n",
    "            ret += self.__print(node.rchild, depth + 1)\n",
    "        ret += \"\\n\" + (\"    \"*depth) + node.get_str()\n",
    "        if node.lchild:\n",
    "            ret += self.__print(node.lchild, depth + 1)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets test our code for the given example in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load the Iris dataset\n",
    "tdata=pd.read_csv('./iris.data', header=None)\n",
    "tdata.columns=['SepalLength','SepalWidth','PetalLength','PetalWidth','Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tx=tdata['SepalLength'].dropna()\n",
    "tx[(tdata['SepalLength']>=4.3) & (tdata['SepalLength']<=5.2)]='a1'\n",
    "tx[(tdata['SepalLength']>5.2) & (tdata['SepalLength']<=6.1)]='a2'\n",
    "tx[(tdata['SepalLength']>6.1) & (tdata['SepalLength']<=7.0)]='a3'\n",
    "tx[(tdata['SepalLength']>7.0) & (tdata['SepalLength']<=7.9)]='a4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a1' 'a1' 'a1' 'a1' 'a1' 'a2' 'a1' 'a1' 'a1' 'a1' 'a2' 'a1' 'a1' 'a1' 'a2'\n",
      " 'a2' 'a2' 'a1' 'a2' 'a1' 'a2' 'a1' 'a1' 'a1' 'a1' 'a1' 'a1' 'a1' 'a1' 'a1'\n",
      " 'a1' 'a2' 'a1' 'a2' 'a1' 'a1' 'a2' 'a1' 'a1' 'a1' 'a1' 'a1' 'a1' 'a1' 'a1'\n",
      " 'a1' 'a1' 'a1' 'a2' 'a1' 'a3' 'a3' 'a3' 'a2' 'a3' 'a2' 'a3' 'a1' 'a3' 'a1'\n",
      " 'a1' 'a2' 'a2' 'a2' 'a2' 'a3' 'a2' 'a2' 'a3' 'a2' 'a2' 'a2' 'a3' 'a2' 'a3'\n",
      " 'a3' 'a3' 'a3' 'a2' 'a2' 'a2' 'a2' 'a2' 'a2' 'a2' 'a2' 'a3' 'a3' 'a2' 'a2'\n",
      " 'a2' 'a2' 'a2' 'a1' 'a2' 'a2' 'a2' 'a3' 'a1' 'a2' 'a3' 'a2' 'a4' 'a3' 'a3'\n",
      " 'a4' 'a1' 'a4' 'a3' 'a4' 'a3' 'a3' 'a3' 'a2' 'a2' 'a3' 'a3' 'a4' 'a4' 'a2'\n",
      " 'a3' 'a2' 'a4' 'a3' 'a3' 'a4' 'a3' 'a2' 'a3' 'a4' 'a4' 'a4' 'a3' 'a3' 'a2'\n",
      " 'a4' 'a3' 'a3' 'a2' 'a3' 'a3' 'a3' 'a2' 'a3' 'a3' 'a3' 'a3' 'a3' 'a3' 'a2']\n",
      "['Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor']\n"
     ]
    }
   ],
   "source": [
    "print tx.values\n",
    "Y=tdata['Class'].dropna()\n",
    "Y[Y=='Iris-virginica']='Iris-versicolor'\n",
    "Y=Y.values\n",
    "print Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "\n",
      "('a1',) 0.508690715247\n"
     ]
    }
   ],
   "source": [
    "%pdb off\n",
    "dt=DecisionTree(0.95,5,5)\n",
    "split, gain, Xlidx, Xridx = dt.evaluate_categorical_attribute(tx,Y)\n",
    "print \n",
    "print split, gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "084088885dd9b2a201b9d9cfca1525cb",
     "grade": true,
     "grade_id": "split_gain",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "from nose.tools import assert_almost_equal, assert_almost_equals\n",
    "\n",
    "%pdb off\n",
    "dt=DecisionTree(0.95,5,5)\n",
    "split, gain, Xlidx, Xridx = dt.evaluate_categorical_attribute(tx,Y)\n",
    "\n",
    "\n",
    "assert_almost_equal('a1', split[0])\n",
    "assert_almost_equal(gain, 0.51, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "383870e8c1eb2fff34369701c8826344",
     "grade": true,
     "grade_id": "acc",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_greater_equal\n",
    "Xtrain,Ytrain,Xtest,Ytest=t.split_data(X,Y)\n",
    "feat=np.arange(2)\n",
    "dt=DecisionTree(0.95,5,10)\n",
    "dt.train(Xtrain[:,feat],Ytrain)\n",
    "\n",
    "\n",
    "pclasses=dt.predict(Xtest[:,feat])\n",
    "acc = np.sum(pclasses==Ytest)/float(Ytest.shape[0])\n",
    "\n",
    "assert_greater_equal(acc, 0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "397b57ec6292e7f23cd31d0ad97103fe",
     "grade": true,
     "grade_id": "acc_all",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_greater_equal\n",
    "Xtrain,Ytrain,Xtest,Ytest=t.split_data(X,Y)\n",
    "\n",
    "dt=DecisionTree(0.95,5,10)\n",
    "dt.train(Xtrain,Ytrain)\n",
    "\n",
    "pclasses=dt.predict(Xtest)\n",
    "acc = np.sum(pclasses==Ytest)/float(Ytest.shape[0])\n",
    "\n",
    "assert_greater_equal(acc, 0.90)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
